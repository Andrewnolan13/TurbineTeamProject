{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining: {'daily': 9980.0, 'hourly': 4995.0, 'minutely': 600}\n",
      "API counts: 1.0\n",
      "https://archive-api.open-meteo.com/v1/archive?cell_selection=nearest&daily=temperature_2m_mean,wind_speed_10m_max&end_date=2020-01-02&hourly=temperature_2m,wind_speed_10m&latitude=53.98352&longitude=-6.39139&start_date=2020-01-01&wind_speed_unit=ms\n",
      "[{'latitude': 53.954304, 'longitude': -6.4410095, 'generationtime_ms': 0.06258487701416016, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 15.0, 'daily_units': {'time': 'iso8601', 'temperature_2m_mean': '째C', 'wind_speed_10m_max': 'km/h'}, 'daily': {'time': ['2020-01-01', '2020-01-02'], 'temperature_2m_mean': [5.3, 9.5], 'wind_speed_10m_max': [13.7, 26.1]}}, {'latitude': 53.98352, 'longitude': -6.39139, 'generationtime_ms': -10.0, 'utc_offset_seconds': -10, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': -9999, 'hourly_units': {'time': 'iso8601', 'temperature_2m_mean': '째C', 'wind_speed_10m_max': 'km/h'}, 'hourly': {'time': ['2020-01-01T00:00:00', '2020-01-01T01:00:00', '2020-01-01T02:00:00', '2020-01-01T03:00:00', '2020-01-01T04:00:00', '2020-01-01T05:00:00', '2020-01-01T06:00:00', '2020-01-01T07:00:00', '2020-01-01T08:00:00', '2020-01-01T09:00:00', '2020-01-01T10:00:00', '2020-01-01T11:00:00', '2020-01-01T12:00:00', '2020-01-01T13:00:00', '2020-01-01T14:00:00', '2020-01-01T15:00:00', '2020-01-01T16:00:00', '2020-01-01T17:00:00', '2020-01-01T18:00:00', '2020-01-01T19:00:00', '2020-01-01T20:00:00', '2020-01-01T21:00:00', '2020-01-01T22:00:00', '2020-01-01T23:00:00', '2020-01-02T00:00:00'], 'temperature_2m': [4.7, 4.9, 5.7, 6.1, 6.2, 6.0, 4.8, 3.7, 2.7, 3.7, 4.3, 5.0, 6.3, 6.6, 6.9, 6.7, 5.7, 5.1, 4.8, 4.8, 5.0, 5.4, 6.3, 6.9, 7.6], 'wind_speed_10m': [1.64, 1.36, 1.8, 2.15, 2.5, 2.2, 2.06, 1.91, 1.87, 2.35, 2.81, 3.0, 2.8, 3.3, 3.5, 3.5, 3.2, 3.04, 3.23, 3.11, 3.08, 3.32, 3.61, 3.81, 4.02]}}]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from src import WindSpeedUnit, ForecastAPI, ForecastCurrent, HistoricalAPI, HistoricalDaily, HistoricalHourly\n",
    "import src\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "f = HistoricalAPI()\n",
    "f.latitude, f.longitude = (53.98352, -6.39139) #src.GEO_COORDINATES.DUNDALK_IT.value\n",
    "f.wind_speed_unit = WindSpeedUnit.METERS_PER_SECOND\n",
    "f.daily = [HistoricalDaily.TEMPERATURE_2M_MEAN, HistoricalDaily.WIND_SPEED_10M_MAX]\n",
    "# f.daily = list(HistoricalDaily._member_map_.values())\n",
    "f.hourly = [HistoricalHourly.TEMPERATURE_2M, HistoricalHourly.WIND_SPEED_10M]\n",
    "# f.hourly = list(HistoricalHourly._member_map_.values())\n",
    "f.start_date = dt.datetime(2020, 1, 1)\n",
    "f.end_date = dt.datetime(2020, 1, 2)\n",
    "f.cell_selection = src.enums.CellSelection.NEAREST\n",
    "\n",
    "response = f.request()\n",
    "print(f.build_url())\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'latitude': 53.954304,\n",
       "  'longitude': -6.4410095,\n",
       "  'generationtime_ms': 0.06258487701416016,\n",
       "  'utc_offset_seconds': 0,\n",
       "  'timezone': 'GMT',\n",
       "  'timezone_abbreviation': 'GMT',\n",
       "  'elevation': 15.0,\n",
       "  'daily_units': {'time': 'iso8601',\n",
       "   'temperature_2m_mean': '째C',\n",
       "   'wind_speed_10m_max': 'km/h'},\n",
       "  'daily': {'time': ['2020-01-01', '2020-01-02'],\n",
       "   'temperature_2m_mean': [5.3, 9.5],\n",
       "   'wind_speed_10m_max': [13.7, 26.1]}},\n",
       " {'latitude': 53.98352,\n",
       "  'longitude': -6.39139,\n",
       "  'generationtime_ms': -10.0,\n",
       "  'utc_offset_seconds': -10,\n",
       "  'timezone': 'GMT',\n",
       "  'timezone_abbreviation': 'GMT',\n",
       "  'elevation': -9999,\n",
       "  'hourly_units': {'time': 'iso8601',\n",
       "   'temperature_2m_mean': '째C',\n",
       "   'wind_speed_10m_max': 'km/h'},\n",
       "  'hourly': {'time': ['2020-01-01T00:00:00',\n",
       "    '2020-01-01T01:00:00',\n",
       "    '2020-01-01T02:00:00',\n",
       "    '2020-01-01T03:00:00',\n",
       "    '2020-01-01T04:00:00',\n",
       "    '2020-01-01T05:00:00',\n",
       "    '2020-01-01T06:00:00',\n",
       "    '2020-01-01T07:00:00',\n",
       "    '2020-01-01T08:00:00',\n",
       "    '2020-01-01T09:00:00',\n",
       "    '2020-01-01T10:00:00',\n",
       "    '2020-01-01T11:00:00',\n",
       "    '2020-01-01T12:00:00',\n",
       "    '2020-01-01T13:00:00',\n",
       "    '2020-01-01T14:00:00',\n",
       "    '2020-01-01T15:00:00',\n",
       "    '2020-01-01T16:00:00',\n",
       "    '2020-01-01T17:00:00',\n",
       "    '2020-01-01T18:00:00',\n",
       "    '2020-01-01T19:00:00',\n",
       "    '2020-01-01T20:00:00',\n",
       "    '2020-01-01T21:00:00',\n",
       "    '2020-01-01T22:00:00',\n",
       "    '2020-01-01T23:00:00',\n",
       "    '2020-01-02T00:00:00'],\n",
       "   'temperature_2m': [4.7,\n",
       "    4.9,\n",
       "    5.7,\n",
       "    6.1,\n",
       "    6.2,\n",
       "    6.0,\n",
       "    4.8,\n",
       "    3.7,\n",
       "    2.7,\n",
       "    3.7,\n",
       "    4.3,\n",
       "    5.0,\n",
       "    6.3,\n",
       "    6.6,\n",
       "    6.9,\n",
       "    6.7,\n",
       "    5.7,\n",
       "    5.1,\n",
       "    4.8,\n",
       "    4.8,\n",
       "    5.0,\n",
       "    5.4,\n",
       "    6.3,\n",
       "    6.9,\n",
       "    7.6],\n",
       "   'wind_speed_10m': [1.64,\n",
       "    1.36,\n",
       "    1.8,\n",
       "    2.15,\n",
       "    2.5,\n",
       "    2.2,\n",
       "    2.06,\n",
       "    1.91,\n",
       "    1.87,\n",
       "    2.35,\n",
       "    2.81,\n",
       "    3.0,\n",
       "    2.8,\n",
       "    3.3,\n",
       "    3.5,\n",
       "    3.5,\n",
       "    3.2,\n",
       "    3.04,\n",
       "    3.23,\n",
       "    3.11,\n",
       "    3.08,\n",
       "    3.32,\n",
       "    3.61,\n",
       "    3.81,\n",
       "    4.02]}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://archive-api.open-meteo.com/v1/archive?cell_selection=nearest&daily=temperature_2m_mean,wind_speed_10m_max&end_date=2020-01-02&hourly=temperature_2m,wind_speed_10m&latitude=50.98352&longitude=6.39139&latitude=53.98352&longitude=-6.39139&start_date=2020-01-01&wind_speed_unit=ms'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://archive-api.open-meteo.com/v1/archive?cell_selection=nearest&daily=temperature_2m_mean,wind_speed_10m_max&end_date=2020-01-02&hourly=temperature_2m,wind_speed_10m&latitude=50.98352&longitude=6.39139&latitude=53.98352&longitude=-6.39139&start_date=2020-01-01&wind_speed_unit=ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.657142857142858"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive-api.open-meteo.com/v1/archive?latitude=52.0&longitude=12.0&latitude=53.98352&longitude=-6.39139&start_date=2025-02-01&end_date=2025-02-19&hourly=temperature_2m,relative_humidity_2m,dew_point_2m,apparent_temperature,precipitation,rain,snowfall,snow_depth,weather_code,pressure_msl,surface_pressure,cloud_cover,cloud_cover_low,cloud_cover_mid,cloud_cover_high,et0_fao_evapotranspiration,vapour_pressure_deficit,wind_speed_10m,wind_speed_100m,wind_direction_10m,wind_direction_100m,wind_gusts_10m,soil_temperature_0_to_7cm,soil_temperature_7_to_28cm,soil_temperature_28_to_100cm,soil_temperature_100_to_255cm,soil_moisture_0_to_7cm,soil_moisture_7_to_28cm,soil_moisture_28_to_100cm,soil_moisture_100_to_255cm,boundary_layer_height,wet_bulb_temperature_2m,total_column_integrated_water_vapour,is_day,sunshine_duration,albedo,snow_depth_water_equivalent&daily=weather_code,temperature_2m_max,temperature_2m_min,temperature_2m_mean,apparent_temperature_max,apparent_temperature_min,apparent_temperature_mean,sunrise,sunset,daylight_duration,sunshine_duration,precipitation_sum,rain_sum,snowfall_sum,precipitation_hours,wind_speed_10m_max,wind_gusts_10m_max,wind_direction_10m_dominant,shortwave_radiation_sum,et0_fao_evapotranspiration&wind_speed_unit=ms&timezone=auto'\n",
    "src.weather.utils.ApiCounter.calculate_call_weight_from_url(url) #3718.842 is the answer. It's wrong though.\n",
    "# src.GEO_COORDINATES.DUNDALK_IT.value\n",
    "\n",
    "# pd.read_pickle('historical.pkl').longitude[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32042"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "parsedParams = src.weather.utils.ApiCounter.parse_url_params(url)\n",
    "startDate = dt.datetime.strptime(parsedParams['start_date'], '%Y-%m-%d')#.strftime('%Y-%m-%d %H:%M:%S')\n",
    "endDate = dt.datetime.strptime(parsedParams['end_date'], '%Y-%m-%d')#.strftime('%Y-%m-%d %H:%M:%S')\n",
    "parsedParams['start_date'] = startDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "parsedParams['end_date'] = endDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "queryDaily = pd.DataFrame(data = pd.date_range(start=startDate, end=endDate, freq='D'), columns=['time'])\n",
    "queryDaily = queryDaily.merge(pd.DataFrame(data = parsedParams['daily'],columns = ['parameter']), how='cross')\n",
    "queryDaily = queryDaily.merge(\n",
    "    pd.DataFrame(dict(latitude = parsedParams['latitude'], longitude = parsedParams['longitude'])),\n",
    "    how='cross')\n",
    "queryDaily.time = queryDaily.time.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "queryHourly = pd.DataFrame(data = pd.date_range(start=startDate,end=endDate, freq='h'), columns=['time'])\n",
    "queryHourly = queryHourly.merge(pd.DataFrame(data = parsedParams['hourly'],columns = ['parameter']), how='cross')\n",
    "queryHourly = queryHourly.merge(\n",
    "    pd.DataFrame(dict(latitude = parsedParams['latitude'], longitude = parsedParams['longitude'])),\n",
    "    how='cross')\n",
    "queryHourly.time = queryHourly.time.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#ensure dtypes\n",
    "queryDaily['time'] = queryDaily['time'].astype('str')\n",
    "queryDaily['parameter'] = queryDaily['parameter'].astype('str')\n",
    "queryDaily['latitude'] = queryDaily['latitude'].astype('float')\n",
    "queryDaily['longitude'] = queryDaily['longitude'].astype('float')\n",
    "\n",
    "queryHourly['time'] = queryHourly['time'].astype('str')\n",
    "queryHourly['parameter'] = queryHourly['parameter'].astype('str')\n",
    "queryHourly['latitude'] = queryHourly['latitude'].astype('float')\n",
    "queryHourly['longitude'] = queryHourly['longitude'].astype('float')\n",
    "\n",
    "# make stging tables\n",
    "conn = f._conn\n",
    "cursor = conn.cursor()\n",
    "\n",
    "hourlyStageCommand = '''\n",
    "CREATE TABLE IF NOT EXISTS hourly_historical_weather_staging_table(\n",
    "    time TEXT,\n",
    "    parameter TEXT,\n",
    "    latitude REAL,\n",
    "    longitude REAL\n",
    ");\n",
    "'''\n",
    "cursor.execute(hourlyStageCommand)\n",
    "conn.commit()\n",
    "\n",
    "dailyStageCommand = '''\n",
    "CREATE TABLE IF NOT EXISTS daily_historical_weather_staging_table(\n",
    "    time TEXT,\n",
    "    parameter TEXT,\n",
    "    latitude REAL,\n",
    "    longitude REAL\n",
    ");\n",
    "'''\n",
    "cursor.execute( dailyStageCommand)\n",
    "conn.commit()\n",
    "\n",
    "#insert data\n",
    "queryDaily.to_sql('daily_historical_weather_staging_table', conn, if_exists='replace', index=False)\n",
    "queryHourly.to_sql('hourly_historical_weather_staging_table', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a command that joins the staging table (request table) with the historical data and then pull it out\n",
    "EPSILON = 1E-12\n",
    "# dailySearchCommand = '''\n",
    "# SELECT * FROM (\n",
    "#         SELECT * FROM daily_historical_weather_data\n",
    "#         WHERE time BETWEEN ? AND ?\n",
    "#     ) AS DAILY\n",
    "# LEFT JOIN daily_historical_weather_staging_table\n",
    "# ON daily_historical_weather_staging_table.time = DAILY.time\n",
    "# AND daily_historical_weather_staging_table.parameter = DAILY.parameter\n",
    "# AND daily_historical_weather_staging_table.latitude = DAILY.latitude\n",
    "# AND daily_historical_weather_staging_table.longitude = DAILY.longitude\n",
    "# '''\n",
    "\n",
    "dailySearchCommand = f'''\n",
    "SELECT\n",
    "    COALESCE(DAILY.time, daily_historical_weather_staging_table.time) AS time,\n",
    "    COALESCE(DAILY.parameter, daily_historical_weather_staging_table.parameter) AS parameter,\n",
    "    COALESCE(DAILY.latitude, daily_historical_weather_staging_table.latitude) AS latitude,\n",
    "    COALESCE(DAILY.longitude, daily_historical_weather_staging_table.longitude) AS longitude,\n",
    "    DAILY.value\n",
    "FROM (\n",
    "    SELECT time, parameter, latitude, longitude, value\n",
    "    FROM daily_historical_weather_data\n",
    "    WHERE time BETWEEN ? AND ?\n",
    ") AS DAILY\n",
    "RIGHT JOIN daily_historical_weather_staging_table\n",
    "ON daily_historical_weather_staging_table.time = DAILY.time\n",
    "AND daily_historical_weather_staging_table.parameter = DAILY.parameter\n",
    "AND ABS(daily_historical_weather_staging_table.latitude - DAILY.latitude) < {EPSILON}\n",
    "AND ABS(daily_historical_weather_staging_table.longitude - DAILY.longitude) < {EPSILON}\n",
    "'''\n",
    "responseDaily = pd.read_sql_query(dailySearchCommand, conn, params=[parsedParams['start_date'], parsedParams['end_date']])\n",
    "\n",
    "\n",
    "hourlySearchCommand = f'''\n",
    "SELECT \n",
    "    COALESCE(HOURLY.time, hourly_historical_weather_staging_table.time) AS time,\n",
    "    COALESCE(HOURLY.parameter, hourly_historical_weather_staging_table.parameter) AS parameter,\n",
    "    COALESCE(HOURLY.latitude, hourly_historical_weather_staging_table.latitude) AS latitude,\n",
    "    COALESCE(HOURLY.longitude, hourly_historical_weather_staging_table.longitude) AS longitude,\n",
    "    HOURLY.value\n",
    "FROM (\n",
    "    SELECT time, parameter, latitude, longitude, value\n",
    "    FROM hourly_historical_weather_data\n",
    "    WHERE time BETWEEN ? AND ?\n",
    ") AS HOURLY\n",
    "RIGHT JOIN hourly_historical_weather_staging_table\n",
    "ON hourly_historical_weather_staging_table.time = HOURLY.time\n",
    "AND hourly_historical_weather_staging_table.parameter = HOURLY.parameter\n",
    "AND ABS(hourly_historical_weather_staging_table.latitude - HOURLY.latitude) < {EPSILON}\n",
    "AND ABS(hourly_historical_weather_staging_table.longitude - HOURLY.longitude) < {EPSILON}\n",
    "'''\n",
    "\n",
    "responseHourly = pd.read_sql_query(hourlySearchCommand, conn, params=[parsedParams['start_date'], parsedParams['end_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foundHourly.loc[lambda s:s.isna().any(axis=1)]\n",
    "foundHourly = responseHourly.copy().loc[lambda s:s.value.notna()]\n",
    "foundDaily = responseDaily.copy().loc[lambda s:s.value.notna()]\n",
    "notFoundHourly = responseHourly.copy().loc[lambda s:s.value.isna()]\n",
    "notFoundDaily = responseDaily.copy().loc[lambda s:s.value.isna()]\n",
    "\n",
    "# now what? make a serparate requests for the missing data. No, too computationally expensive to split up all the data.\n",
    "# Furthermore, I will get punished by the api for splitting the requests up too finely.\n",
    "# this means I'd have to spend ages figuring out how to optimally split the requests up to minimize api calling.\n",
    "# I will just look at at it like this: \n",
    "    # I am expecting to make historical ts requests with long ranges, freqently.\n",
    "    # I am assuming that 10% of the data is missing. And what is present is continuous. So 'ill just request from min notFoundDaily.time.min() onwards.\n",
    "    # after submitting to database I will tell db to drop duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notFoundHourly = notFoundHourly.assign(geo = lambda s: s.latitude.astype('str') + ', ' + s.longitude.astype('str'))\n",
    "# notFoundHourly.sort_values(by = 'geo parameter time'.split(), inplace=True, ignore_index=True)\n",
    "# notFoundHourly['timeObj'] = pd.to_datetime(notFoundHourly.time)\n",
    "\n",
    "\n",
    "# for key,grp in notFoundHourly.groupby('geo parameter'.split()):\n",
    "#     break\n",
    "# # (grp.timeObj.shift(-1)-grp.timeObj).fillna(pd.Timedelta(hours=1))\n",
    "# grp['dt'] = (grp.timeObj.shift(-1)-grp.timeObj).fillna(pd.Timedelta(hours=1))\n",
    "# grp['dt'] = grp.dt.dt.total_seconds()/3600\n",
    "# grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = notFoundHourly.copy()\n",
    "df = df.assign(geo = lambda s: s.latitude.astype('str') + ',' + s.longitude.astype('str'))\n",
    "df.sort_values(by = 'geo parameter time'.split(), inplace=True, ignore_index=True)\n",
    "df['timeObj'] = pd.to_datetime(df.time)\n",
    "df = df.groupby('geo timeObj'.split()).agg(parameter = ('parameter',','.join)).reset_index()\n",
    "df = df.groupby('geo parameter'.split()).agg(start_date = ('timeObj','min'), end_date = ('timeObj','max')).reset_index()\n",
    "df = df.groupby('parameter start_date end_date'.split()).agg(geo = ('geo',' '.join)).reset_index()\n",
    "\n",
    "row = df.iloc[0]\n",
    "for geo in row['geo'].split(' '):\n",
    "    latitude, longitude = geo.split(',')\n",
    "    hourly = [HistoricalHourly._value2member_map_[value] for value in row['parameter'].split(',')]\n",
    "    sd = row['start_date'].to_pydatetime()\n",
    "    ed = row['end_date'].to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = foundHourly.copy()\n",
    "df = df.assign(geo = lambda s: s.latitude.astype('str') + ',' + s.longitude.astype('str'))\n",
    "gdf = df.copy()\n",
    "gdf = gdf.assign(geo = lambda s: s.latitude.astype('str') + ',' + s.longitude.astype('str'))\n",
    "res = (\n",
    "    gdf.groupby('geo'.split())\n",
    "        .agg(\n",
    "                latitude = ('latitude','first'), \n",
    "                longitude = ('longitude','first'),\n",
    "            )\n",
    "        .assign(\n",
    "                generationtime_ms = -10.0,\n",
    "                utc_offset_seconds= -10,\n",
    "                timezone= 'GMT',\n",
    "                timezone_abbreviation= 'GMT',\n",
    "                elevation= -9999,\n",
    "                daily_units= lambda df:df.shape[0]*[{'time': 'iso8601','temperature_2m_mean': '째C','wind_speed_10m_max': 'km/h'}],            \n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .to_dict(orient='records')\n",
    ")\n",
    "df.time = pd.to_datetime(df.time).dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "for dict_,(_,grp) in zip(res,df.groupby('geo')):\n",
    "    dict_['daily'] = grp.pivot_table(index = 'time', columns = 'parameter', values = 'value', aggfunc='first').reset_index().to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
